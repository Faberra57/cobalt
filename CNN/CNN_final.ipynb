{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7d0f1e",
   "metadata": {
    "papermill": {
     "duration": 0.004244,
     "end_time": "2024-11-19T11:11:55.786476",
     "exception": false,
     "start_time": "2024-11-19T11:11:55.782232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64792744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:11:55.795056Z",
     "iopub.status.busy": "2024-11-19T11:11:55.794738Z",
     "iopub.status.idle": "2024-11-19T11:11:56.605459Z",
     "shell.execute_reply": "2024-11-19T11:11:56.604756Z"
    },
    "papermill": {
     "duration": 0.817194,
     "end_time": "2024-11-19T11:11:56.607336",
     "exception": false,
     "start_time": "2024-11-19T11:11:55.790142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'dataset')))\n",
    "\n",
    "data_path = '../dataset/archive/BBBC005_v1_images/BBBC005_v1_images'\n",
    "\n",
    "def load_data_image(folder=data_path):\n",
    "    \n",
    "    # folder = 'dataset/archive/BBBC005_v1_images'\n",
    "    img_list = os.listdir(folder)\n",
    "    img_list.remove('.htaccess') # remove this file\n",
    "    \n",
    "\n",
    "    def get_num_cells(x):\n",
    "        #SIMCEPImages_A13_C53_F1_s09_w2.TIF -> C53\n",
    "\n",
    "        a = x.split('_') # e.g. ['SIMCEPImages', 'A13', 'C53', 'F1', 's09', 'w2.TIF']\n",
    "        b = a[2] # e.g. C53\n",
    "        num_cells = int(b[1:]) # e.g. 53\n",
    "        \n",
    "        return num_cells\n",
    "        \n",
    "    df = pd.DataFrame({'image_id': img_list})\n",
    "    df['image_id'] = df[df['image_id'] != '.htaccess']\n",
    "    df['nb_cells'] = df['image_id'].apply(get_num_cells)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b05a9",
   "metadata": {
    "papermill": {
     "duration": 0.003524,
     "end_time": "2024-11-19T11:11:56.614914",
     "exception": false,
     "start_time": "2024-11-19T11:11:56.611390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58092875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:11:56.623365Z",
     "iopub.status.busy": "2024-11-19T11:11:56.622989Z",
     "iopub.status.idle": "2024-11-19T11:12:03.311495Z",
     "shell.execute_reply": "2024-11-19T11:12:03.310512Z"
    },
    "papermill": {
     "duration": 6.694942,
     "end_time": "2024-11-19T11:12:03.313409",
     "exception": false,
     "start_time": "2024-11-19T11:11:56.618467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame avec deux colonnes : 'path' et 'label'.\n",
    "            transform (callable, optional): Transformations à appliquer aux images.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Charger l'image\n",
    "        img_path = self.dataframe.iloc[idx, 0]  # Supposons que la première colonne est 'path'\n",
    "        label = self.dataframe.iloc[idx, 1]# Supposons que la deuxième colonne est 'label'\n",
    "        \n",
    "        image = Image.open(data_path + '/' + img_path)\n",
    "        # Appliquer les transformations, si elles existent\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = torch.tensor(label , dtype = torch.float32)\n",
    "        return image, label\n",
    "\n",
    "df_data = load_data_image()\n",
    "\n",
    "# Proportions pour train, valid, test\n",
    "train_ratio = 0.7\n",
    "valid_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Étape 1 : Diviser entre train et temp (valid+test)\n",
    "train_df, temp_df = train_test_split(df_data, test_size=(1 - train_ratio), random_state=42, shuffle=True)\n",
    "\n",
    "# Étape 2 : Diviser temp entre valid et test\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=(test_ratio / (test_ratio + valid_ratio)), random_state=42)\n",
    "\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = CustomImageDataset(dataframe=train_df, transform=transform)\n",
    "valid_dataset = CustomImageDataset(dataframe=valid_df, transform=transform)\n",
    "test_dataset = CustomImageDataset(dataframe=test_df, transform=transform)\n",
    "\n",
    "\n",
    "batch_size = 16 # adapté à la taille de la mémoire\n",
    "torch.manual_seed(42)\n",
    "train_dataloader= DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "print(f'Data Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd80fdf",
   "metadata": {
    "papermill": {
     "duration": 0.003514,
     "end_time": "2024-11-19T11:12:03.322005",
     "exception": false,
     "start_time": "2024-11-19T11:12:03.318491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f73b02ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:12:03.330523Z",
     "iopub.status.busy": "2024-11-19T11:12:03.330094Z",
     "iopub.status.idle": "2024-11-19T11:12:03.334925Z",
     "shell.execute_reply": "2024-11-19T11:12:03.334071Z"
    },
    "papermill": {
     "duration": 0.010884,
     "end_time": "2024-11-19T11:12:03.336508",
     "exception": false,
     "start_time": "2024-11-19T11:12:03.325624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv_layers=3 # Number of convolutional layers\n",
    "stride = 1 # Stride for each convolutional layer\n",
    "padding = 1 # Padding for each convolutional layer\n",
    "dilation = 1 # Dilation for each convolutional layer \n",
    "\n",
    "filters_per_layer=[64,128,256] # Number of filters per convolutional layer\n",
    "kernel_sizes=[5,10,5] # Kernel size for each convolutional layer\n",
    "pool_size=2 # Pooling size\n",
    "dropout_rate_conv=0.2 # Dropout rate for each convolutional layers\n",
    "\n",
    "\n",
    "dense_layers=1 # Number of dense layers\n",
    "dense_units=[1] # Number of units per dense layer\n",
    "dropout_rate_fc = [0.5] # Dropout rate for dense layer\n",
    "\n",
    "alpha = 0.1 # alpha of the LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c44bc99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:12:03.344939Z",
     "iopub.status.busy": "2024-11-19T11:12:03.344665Z",
     "iopub.status.idle": "2024-11-19T11:12:04.167507Z",
     "shell.execute_reply": "2024-11-19T11:12:04.166662Z"
    },
    "papermill": {
     "duration": 0.829213,
     "end_time": "2024-11-19T11:12:04.169234",
     "exception": false,
     "start_time": "2024-11-19T11:12:03.340021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiated\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 126, 126]           1,664\n",
      "       BatchNorm2d-2         [-1, 64, 126, 126]             128\n",
      "         LeakyReLU-3         [-1, 64, 126, 126]               0\n",
      "           Dropout-4         [-1, 64, 126, 126]               0\n",
      "            Conv2d-5        [-1, 128, 119, 119]         819,328\n",
      "       BatchNorm2d-6        [-1, 128, 119, 119]             256\n",
      "         LeakyReLU-7        [-1, 128, 119, 119]               0\n",
      "         MaxPool2d-8          [-1, 128, 59, 59]               0\n",
      "           Dropout-9          [-1, 128, 59, 59]               0\n",
      "           Conv2d-10          [-1, 256, 57, 57]         819,456\n",
      "      BatchNorm2d-11          [-1, 256, 57, 57]             512\n",
      "        LeakyReLU-12          [-1, 256, 57, 57]               0\n",
      "          Dropout-13          [-1, 256, 57, 57]               0\n",
      "           Linear-14                    [-1, 1]         831,745\n",
      "================================================================\n",
      "Total params: 2,473,089\n",
      "Trainable params: 2,473,089\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 104.68\n",
      "Params size (MB): 9.43\n",
      "Estimated Total Size (MB): 114.17\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 nb_conv_layers,\n",
    "                 stride,\n",
    "                 padding,\n",
    "                 dilation, \n",
    "                 filters_per_layer, \n",
    "                 kernel_sizes,\n",
    "                 pool_size, \n",
    "                 dropout_rate_conv,\n",
    "                 nb_dense_layers, \n",
    "                 dense_units, \n",
    "                 dropout_rate_fc,\n",
    "                 alpha,\n",
    "                 img_height,\n",
    "                 img_width):\n",
    "        \n",
    "        super(CNN, self).__init__()\n",
    "        self.nb_conv_layers = nb_conv_layers\n",
    "        self.nb_dense_layers = nb_dense_layers\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.pool_layers = nn.ModuleList()\n",
    "        self.dropout_conv = nn.ModuleList()\n",
    "        self.bn2 = nn.ModuleList()\n",
    "        self.dense_layers = nn.ModuleList()\n",
    "        self.dropout_fc = nn.ModuleList()\n",
    "        self.relu = nn.LeakyReLU(negative_slope=alpha)\n",
    "\n",
    "        # Convolutional layers\n",
    "        in_channels = 1  # Nombre de canaux d'entrée (ex. : images en niveaux de gris)\n",
    "        for i in range(nb_conv_layers):\n",
    "            conv_layer = nn.Conv2d(in_channels=in_channels, \n",
    "                                   out_channels=filters_per_layer[i], \n",
    "                                   kernel_size=kernel_sizes[i],\n",
    "                                   stride=stride,\n",
    "                                   padding=padding,\n",
    "                                   dilation=dilation)\n",
    "            self.conv_layers.append(conv_layer)\n",
    "            self.bn2.append(nn.BatchNorm2d(filters_per_layer[i]))\n",
    "            self.pool_layers.append(nn.MaxPool2d(pool_size))\n",
    "            self.dropout_conv.append(nn.Dropout(dropout_rate_conv))\n",
    "            in_channels = filters_per_layer[i]\n",
    "\n",
    "        # Calculate the flattened feature map size\n",
    "        self.flattened_size = self._get_flattened_size(img_height, img_width, kernel_sizes, stride, padding, dilation, pool_size)\n",
    "\n",
    "        # Dense layers\n",
    "        for i in range(nb_dense_layers):\n",
    "            if i == 0:\n",
    "                dense_layer = nn.Linear(self.flattened_size, dense_units[i])\n",
    "            else:\n",
    "                dense_layer = nn.Linear(dense_units[i - 1], dense_units[i])\n",
    "            self.dense_layers.append(dense_layer)\n",
    "            self.dropout_fc.append(nn.Dropout(dropout_rate_fc[i]))\n",
    "\n",
    "    def _get_flattened_size(self, height, width, kernel_sizes, stride, padding, dilation, pool_size):\n",
    "        for i in range(self.nb_conv_layers):\n",
    "            height = (height + 2 * padding - dilation * (kernel_sizes[i] - 1) - 1) // stride + 1\n",
    "            width = (width + 2 * padding - dilation * (kernel_sizes[i] - 1) - 1) // stride + 1\n",
    "            if i % 2 == 1:\n",
    "                height //= pool_size\n",
    "                width //= pool_size\n",
    "        return height * width * filters_per_layer[-1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        for i in range(self.nb_conv_layers):\n",
    "            x = self.conv_layers[i](x)\n",
    "            x = self.bn2[i](x)\n",
    "            x = self.relu(x)\n",
    "            if i % 2 == 1:\n",
    "                x = self.pool_layers[i](x)\n",
    "            x = self.dropout_conv[i](x)\n",
    "            \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Dense layers\n",
    "        for i in range(self.nb_dense_layers - 1):\n",
    "            x = self.dense_layers[i](x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout_fc[i](x)\n",
    "        x = self.dense_layers[-1](x)\n",
    "        return x\n",
    "\n",
    "model = CNN(nb_conv_layers = conv_layers,\n",
    "            stride = stride,\n",
    "            padding = padding,\n",
    "            dilation = dilation,\n",
    "            filters_per_layer = filters_per_layer,\n",
    "            kernel_sizes = kernel_sizes,\n",
    "            pool_size = pool_size,\n",
    "            dropout_rate_conv = dropout_rate_conv,\n",
    "            nb_dense_layers = dense_layers,\n",
    "            dense_units = dense_units,\n",
    "            dropout_rate_fc = dropout_rate_fc,\n",
    "            alpha = alpha,\n",
    "            img_height = IMG_HEIGHT,\n",
    "            img_width = IMG_WIDTH)\n",
    "\n",
    "print(f'Model instantiated')\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "summary(model, (1,IMG_HEIGHT,IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2729a280",
   "metadata": {
    "papermill": {
     "duration": 0.003657,
     "end_time": "2024-11-19T11:12:04.177021",
     "exception": false,
     "start_time": "2024-11-19T11:12:04.173364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81109fdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:12:04.185683Z",
     "iopub.status.busy": "2024-11-19T11:12:04.185411Z",
     "iopub.status.idle": "2024-11-19T11:12:04.191541Z",
     "shell.execute_reply": "2024-11-19T11:12:04.190840Z"
    },
    "papermill": {
     "duration": 0.012314,
     "end_time": "2024-11-19T11:12:04.193075",
     "exception": false,
     "start_time": "2024-11-19T11:12:04.180761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(\"device : \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e32a0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:12:04.202068Z",
     "iopub.status.busy": "2024-11-19T11:12:04.201606Z",
     "iopub.status.idle": "2024-11-19T11:12:04.208612Z",
     "shell.execute_reply": "2024-11-19T11:12:04.207765Z"
    },
    "papermill": {
     "duration": 0.013201,
     "end_time": "2024-11-19T11:12:04.210220",
     "exception": false,
     "start_time": "2024-11-19T11:12:04.197019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faberra/anaconda3/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58537613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:12:04.219219Z",
     "iopub.status.busy": "2024-11-19T11:12:04.218985Z",
     "iopub.status.idle": "2024-11-19T11:12:04.227867Z",
     "shell.execute_reply": "2024-11-19T11:12:04.227041Z"
    },
    "papermill": {
     "duration": 0.015094,
     "end_time": "2024-11-19T11:12:04.229456",
     "exception": false,
     "start_time": "2024-11-19T11:12:04.214362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_epochs = 70  # Number of epochs to train the model\n",
    "\n",
    "def training(n_epochs, train_dataloader, valid_dataloader, model, criterion, optimizer, scheduler=None):\n",
    "    train_losses, valid_losses = [], []\n",
    "    valid_loss_min = np.inf  # Initialize minimum validation loss as infinity\n",
    "    best_model_state = None  # Variable to store the best model state\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss, valid_loss = 0.0, 0.0  # Reset running losses\n",
    "\n",
    "        # --- Training Phase ---\n",
    "        model.train()  # Set model to training mode\n",
    "        for data, label in train_dataloader:\n",
    "            # Move data and labels to the correct device\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            label = label.unsqueeze(1)  # Ensure label shape matches model output\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "            loss = criterion(output, label)  # Compute loss\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            # Optimizer step\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate training loss\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "        # --- Validation Phase ---\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():  # Disable gradient computation for validation\n",
    "            for data, label in valid_dataloader:\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "                label = label.unsqueeze(1)\n",
    "\n",
    "                # Forward pass\n",
    "                output = model(data)\n",
    "                loss = criterion(output, label)\n",
    "                \n",
    "                # Accumulate validation loss\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "        # Calculate average losses for the epoch\n",
    "        train_loss /= len(train_dataloader.dataset)\n",
    "        valid_loss /= len(valid_dataloader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        # Print epoch statistics\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch: {epoch+1}, LR: {current_lr:.6e}, \"\n",
    "              f\"Training Loss: {train_loss:.6f}, Validation Loss: {valid_loss:.6f}\")\n",
    "\n",
    "        # Check if validation loss improved\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print(f\"Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model ...\")\n",
    "            best_model_state = model.state_dict()\n",
    "            torch.save(best_model_state, '../model/ccn_magique.pt')\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "        # Step the scheduler (if any)\n",
    "        if scheduler:\n",
    "            scheduler.step(valid_loss)\n",
    "\n",
    "    return train_losses, valid_losses, best_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36b23f5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T11:12:04.238211Z",
     "iopub.status.busy": "2024-11-19T11:12:04.237954Z",
     "iopub.status.idle": "2024-11-19T12:57:36.932342Z",
     "shell.execute_reply": "2024-11-19T12:57:36.931339Z"
    },
    "papermill": {
     "duration": 6332.70759,
     "end_time": "2024-11-19T12:57:36.940950",
     "exception": false,
     "start_time": "2024-11-19T11:12:04.233360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart Training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m train_losses, valid_losses , best_model_state \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 32\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(n_epochs, train_dataloader, valid_dataloader, model, criterion, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Gradient clipping to prevent exploding gradients\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Optimizer step\u001b[39;00m\n\u001b[1;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:21\u001b[0m, in \u001b[0;36m_no_grad.<locals>._no_grad_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_no_grad_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/utils/clip_grad.py:98\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     96\u001b[0m         clip_coef_clamped_device \u001b[38;5;241m=\u001b[39m clip_coef_clamped\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m device_grads:\n\u001b[0;32m---> 98\u001b[0m             \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip_coef_clamped_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f'Start Training')\n",
    "\n",
    "\n",
    "\n",
    "train_losses, valid_losses , best_model_state = training(n_epochs, train_dataloader, valid_dataloader, model, criterion, optimizer,scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92fc195",
   "metadata": {
    "papermill": {
     "duration": 0.006595,
     "end_time": "2024-11-19T12:57:36.954340",
     "exception": false,
     "start_time": "2024-11-19T12:57:36.947745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41005489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T12:57:36.969522Z",
     "iopub.status.busy": "2024-11-19T12:57:36.968803Z",
     "iopub.status.idle": "2024-11-19T12:57:36.974892Z",
     "shell.execute_reply": "2024-11-19T12:57:36.974186Z"
    },
    "papermill": {
     "duration": 0.015433,
     "end_time": "2024-11-19T12:57:36.976507",
     "exception": false,
     "start_time": "2024-11-19T12:57:36.961074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluation(model, test_dataloader, criterion):\n",
    "\n",
    "    # initialize lists to monitor test loss and accuracy\n",
    "    test_loss = 0.0\n",
    "    error = 0.0\n",
    "\n",
    "    model.eval() # prep model for evaluation\n",
    "    for data, label in test_dataloader:\n",
    "        data = data.to(device=device, dtype=torch.float32)\n",
    "        label = label.to(device=device, dtype=torch.float32)\n",
    "        \n",
    "        # unsqueeze the label\n",
    "        label = label.unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(data) # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            loss = criterion(output,label)\n",
    "        error += torch.abs(output - label)\n",
    "        test_loss += loss.item()*data.size(0)\n",
    "\n",
    "    # calculate and print avg test loss\n",
    "    test_loss = test_loss/test_dataset.__len__()\n",
    "    mean_error = error/test_dataset.__len__()\n",
    "    print('test Loss: {:.6f}\\n'.format(test_loss))\n",
    "    print('Mean Error of Prediction: {:.6f}'.format(mean_error.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c5b3c3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T12:57:36.991461Z",
     "iopub.status.busy": "2024-11-19T12:57:36.991190Z",
     "iopub.status.idle": "2024-11-19T12:58:45.133048Z",
     "shell.execute_reply": "2024-11-19T12:58:45.132217Z"
    },
    "papermill": {
     "duration": 68.15839,
     "end_time": "2024-11-19T12:58:45.141733",
     "exception": false,
     "start_time": "2024-11-19T12:57:36.983343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rw/pr8ypc3j0fq4c3b12n99pdp00000gn/T/ipykernel_73909/813388524.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model_state = torch.load('../model/ccn_model_magique.pt' , map_location=device)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m best_model_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../model/ccn_model_magique.pt\u001b[39m\u001b[38;5;124m'\u001b[39m , map_location\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(best_model_state)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 19\u001b[0m, in \u001b[0;36mevaluation\u001b[0;34m(model, test_dataloader, criterion)\u001b[0m\n\u001b[1;32m     17\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(output,label)\n\u001b[1;32m     18\u001b[0m     error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(output \u001b[38;5;241m-\u001b[39m label)\n\u001b[0;32m---> 19\u001b[0m     test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39mdata\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# calculate and print avg test loss\u001b[39;00m\n\u001b[1;32m     22\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m test_loss\u001b[38;5;241m/\u001b[39mtest_dataset\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model_state = torch.load('../model/ccn_model_magique.pt' , map_location=device)\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "evaluation(model,test_dataloader,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef696445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:23:20.211856Z",
     "iopub.status.busy": "2024-11-18T21:23:20.211232Z",
     "iopub.status.idle": "2024-11-18T21:23:20.217001Z",
     "shell.execute_reply": "2024-11-18T21:23:20.216099Z",
     "shell.execute_reply.started": "2024-11-18T21:23:20.211825Z"
    },
    "papermill": {
     "duration": 0.006701,
     "end_time": "2024-11-19T12:58:45.155370",
     "exception": false,
     "start_time": "2024-11-19T12:58:45.148669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def l_plot(model, test_dataloader):\n",
    "\n",
    "    # initialize lists to monitor test loss and accuracy\n",
    "    y_prediction = []\n",
    "    x_label = []\n",
    "    model.eval() # prep model for evaluation\n",
    "    for data, label in test_dataloader:\n",
    "        data = data.to(device=device, dtype=torch.float32)\n",
    "        label = label.to(device=device, dtype=torch.float32)\n",
    "        \n",
    "        # unsqueeze the label\n",
    "        label = label.unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(data) # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            y_prediction.append(output.cpu().numpy())\n",
    "            x_label.append(label.cpu().numpy())\n",
    "\n",
    "    return y_prediction , x_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b3c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:23:21.510391Z",
     "iopub.status.busy": "2024-11-18T21:23:21.509741Z",
     "iopub.status.idle": "2024-11-18T21:24:29.787106Z",
     "shell.execute_reply": "2024-11-18T21:24:29.786428Z",
     "shell.execute_reply.started": "2024-11-18T21:23:21.510356Z"
    },
    "papermill": {
     "duration": 0.006608,
     "end_time": "2024-11-19T12:58:45.168724",
     "exception": false,
     "start_time": "2024-11-19T12:58:45.162116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rw/pr8ypc3j0fq4c3b12n99pdp00000gn/T/ipykernel_73818/1252314494.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_state = torch.load(\"../model/cnn_model_magique.pt\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../model/cnn_model_magique.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../model/cnn_model_magique.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(best_state)\n\u001b[1;32m      5\u001b[0m y_prediction , x_label \u001b[38;5;241m=\u001b[39m l_plot(model, test_dataloader)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../model/cnn_model_magique.pt'"
     ]
    }
   ],
   "source": [
    "y_prediction , x_label = l_plot(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82fccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:24:32.977162Z",
     "iopub.status.busy": "2024-11-18T21:24:32.976485Z",
     "iopub.status.idle": "2024-11-18T21:24:33.252537Z",
     "shell.execute_reply": "2024-11-18T21:24:33.251571Z",
     "shell.execute_reply.started": "2024-11-18T21:24:32.977129Z"
    },
    "papermill": {
     "duration": 0.006583,
     "end_time": "2024-11-19T12:58:45.182316",
     "exception": false,
     "start_time": "2024-11-19T12:58:45.175733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_prediction = np.array(y_prediction)\n",
    "x_label = np.array(x_label)\n",
    "\n",
    "\n",
    "y_prediction = y_prediction.ravel()\n",
    "x_label = x_label.ravel()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x = np.linspace(0 , 120 , 10)\n",
    "y =x\n",
    "\n",
    "plt.scatter(x_label , y_prediction)\n",
    "plt.plot(x,y,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71aa787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:30:31.259640Z",
     "iopub.status.busy": "2024-11-18T21:30:31.259306Z",
     "iopub.status.idle": "2024-11-18T21:30:47.992811Z",
     "shell.execute_reply": "2024-11-18T21:30:47.991956Z",
     "shell.execute_reply.started": "2024-11-18T21:30:31.259611Z"
    },
    "papermill": {
     "duration": 0.006691,
     "end_time": "2024-11-19T12:58:45.195742",
     "exception": false,
     "start_time": "2024-11-19T12:58:45.189051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval() # prep model for evaluation\n",
    "i = 0\n",
    "for data, label in test_dataloader:\n",
    "    data = data.to(device=device, dtype=torch.float32)\n",
    "    label = label.to(device=device, dtype=torch.float32)\n",
    "    \n",
    "    # unsqueeze the label\n",
    "    label = label.unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(data) # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        loss = criterion(output,label)\n",
    "        \n",
    "        if i % 100 == 0 :\n",
    "            print(f'True value {label.item()} and the value predict {output.item()}')\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da8dbbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T09:13:45.344487Z",
     "iopub.status.busy": "2024-11-17T09:13:45.344074Z",
     "iopub.status.idle": "2024-11-17T09:13:47.020395Z",
     "shell.execute_reply": "2024-11-17T09:13:47.019364Z",
     "shell.execute_reply.started": "2024-11-17T09:13:45.344447Z"
    },
    "papermill": {
     "duration": 0.006577,
     "end_time": "2024-11-19T12:58:45.209138",
     "exception": false,
     "start_time": "2024-11-19T12:58:45.202561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "\n",
    "image , label = next(iter(train_dataloader))\n",
    "\n",
    "example_input = image[0].unsqueeze(0)\n",
    "model = model.cpu()\n",
    "model.eval()\n",
    "\n",
    "# Chemin d'exportation pour le modèle ONNX\n",
    "onnx_path = \"/kaggle/working/cobalt.onnx\"\n",
    "\n",
    "# Exporter le modèle en ONNX\n",
    "torch.onnx.export(\n",
    "    model,                    # Le modèle PyTorch\n",
    "    example_input,            # Exemple d'entrée\n",
    "    onnx_path,                # Destination du fichier ONNX\n",
    "    export_params=True,       # Inclure les poids dans le fichier ONNX\n",
    "    opset_version=11,         # Version ONNX (généralement >= 11)\n",
    "    do_constant_folding=True, # Activer l'optimisation des constantes\n",
    "    input_names=['input'],    # Nom des entrées du modèle\n",
    "    output_names=['output'],  # Nom des sorties du modèle\n",
    "    dynamic_axes={            # Dimensions dynamiques pour gérer plusieurs tailles d'entrée\n",
    "        'input': {0: 'batch_size'}, \n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Modèle exporté avec succès vers {onnx_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 205933,
     "sourceId": 451637,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 166212,
     "modelInstanceId": 143623,
     "sourceId": 168826,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 166631,
     "modelInstanceId": 144055,
     "sourceId": 169309,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6413.272698,
   "end_time": "2024-11-19T12:58:46.651833",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-19T11:11:53.379135",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
